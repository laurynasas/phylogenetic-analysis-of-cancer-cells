{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will represent results showed in figure 4.5, where we compare clustering algorithm performances in terms of adjusted rand index using different (in size and error) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.metrics import adjusted_rand_score,silhouette_score\n",
    "from k_medoid_clustering import KMedoid\n",
    "from bernoulli_mixture_model import BMM\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper contains widely used methods that we will utilise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper = helpers.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please define the raw data file obtained through simulation or use the existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_dir = \"./populated_data/populated_true_genotypes_10_10_0.01_100.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering methods that should be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering_methods = [\"k_means\",\"slc\",\"bmm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of clusters to split data into, vector size is the length of mutation vector and number of iterations is only applicable for BMM as it will show how many times EM step is iterated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_clusters = 10\n",
    "vector_size = 10\n",
    "number_of_iterations_for_bmm = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-linkage-clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _do_slc(no_clusters, distance_matrix):\n",
    "    labels = fcluster(linkage(distance_matrix, method='complete'), t=no_clusters, criterion='maxclust')\n",
    "\n",
    "    new_data = {}\n",
    "\n",
    "    for cluster_label in labels - 1:\n",
    "        if new_data.get(cluster_label):\n",
    "            new_data[cluster_label] += [map(int, unique_rows.keys()[cluster_label].split(\",\"))]\n",
    "        else:\n",
    "            new_data[cluster_label] = [map(int, unique_rows.keys()[cluster_label].split(\",\"))]\n",
    "\n",
    "    new_data_formatetd = {}\n",
    "    for key, value in new_data.items():\n",
    "        new_value = [','.join(map(str, el)) for el in value]\n",
    "        new_data_formatetd[key] = new_value\n",
    "\n",
    "    return new_data_formatetd, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides labels of true data and allows us to compare them to predicted labels later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_true_labels(unique_rows, full_data_dict):\n",
    "    true_labels = []\n",
    "    for key in unique_rows.keys():\n",
    "        label = helper.get_label_of_cluster(vector=key, full_dict = full_data_dict)\n",
    "        for _ in range(unique_rows[key]):\n",
    "            true_labels.append(label)\n",
    "    return true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs clustering, extracts predicted labels and compares them to true labels using Adjusted Rand Index for all different clustering techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== k_means ==========\n",
      "Adjusted Rand Index:  0.835657873067\n",
      "======== slc ==========\n",
      "Adjusted Rand Index:  0.813922296593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laurynas/workspace/individual_project/analysis_notebooks/analysis/lib/python2.7/site-packages/ipykernel/__main__.py:2: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== bmm ==========\n",
      "Adjusted Rand Index:  0.837396040304\n"
     ]
    }
   ],
   "source": [
    "unique_rows, full_data_dict, full_info = helper.read_simulated_data_file(raw_data_dir)\n",
    "distance_matrix = np.matrix(helper.find_distance_matrix(unique_rows))\n",
    "true_labels = get_true_labels(unique_rows, full_data_dict)\n",
    "\n",
    "for clustering_method in clustering_methods:\n",
    "    \n",
    "    if clustering_method == \"slc\":\n",
    "        clustered_dict, labels = _do_slc(no_clusters, distance_matrix)\n",
    "        predicted_labels = labels-1\n",
    "        \n",
    "    elif clustering_method == \"k_means\":\n",
    "\n",
    "        predefined_kwargs = {\"number_of_clusters\": no_clusters, \"unique_rows\": unique_rows,\n",
    "                             \"full_data_dict\": full_data_dict, \"full_info\": full_info,\n",
    "                             \"vector_size\": vector_size}\n",
    "        k_means_instance = KMedoid(**predefined_kwargs)\n",
    "        clustered_dict = k_means_instance.do_k_means_using_sklearn()\n",
    "\n",
    "        predicted_labels = k_means_instance.get_sklearn_predicted_labels()\n",
    "    elif clustering_method == \"bmm\":\n",
    "        bmm = BMM(no_clusters, unique_rows, full_data_dict, full_info, number_of_iterations_for_bmm)\n",
    "        clustered_dict,predicted_labels = bmm.do_clustering()\n",
    "        \n",
    "    print \"========\",clustering_method,\"==========\"\n",
    "    print \"Adjusted Rand Index: \", adjusted_rand_score(true_labels, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
